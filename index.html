<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="RewardMap">
  <meta name="keywords" content="Visual Reasoning, MLLM, Spatial Reasoning, RL, GRPO">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RewardMap: Tackling Sparse Rewards in Fine-grained Visual Reasoning via Multi-Stage Reinforcement Learning</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://github.com/fscdc/RewardMap">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>
      </div>
    </div>
  </nav>



  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">RewardMap: Tackling Sparse Rewards in Fine-grained Visual Reasoning via Multi-Stage Reinforcement Learning</h1>
            <div class="is-size-5 publication-authors">
                <span class="author-block">
                    <a href="https://fscdc.github.io/">Sicheng Feng</a><sup>1,2†</sup>&#8192;
                  </span>
                  <span class="author-block">
                    <a href="https://songw-zju.github.io/">Song Wang</a><sup>3,2†</sup>&#8192;
                  </span>
                  <span class="author-block">
                    <a href="https://scholar.google.com.hk/citations?user=pQgChLEAAAAJ&hl=zh-CN">Shuyi Ouyang</a><sup>3,2</sup>&#8192;
                  </span>
                  <span class="author-block">
                    <a href="https://ldkong.com/">Lingdong Kong</a><sup>2</sup>&#8192;
                  </span>
                  <span class="author-block">
                    <a href="https://skyesong38.github.io/">Zikai Song</a><sup>4,2</sup>&#8192;
                  </span>
                  <span class="author-block">
                    <a href="https://person.zju.edu.cn/en/jkzhu">Jianke Zhu</a><sup>3</sup>&#8192;
                  </span>
                  <span class="author-block">
                    <a href="http://huanwang.tech">Huan Wang</a><sup>1*</sup>&#8192;
                  </span>
                  <span class="author-block">
                    <a href="https://sites.google.com/site/sitexinchaowang/">Xinchao Wang</a><sup>2</sup>&#8192;
                  </span>                  
            </div>
            <h1 style="font-size:23px;font-weight:bold">2025</h1>

            <div class="is-size-5 publication-authors">
                <span><sup>1</sup>Westlake University, Hangzhou, China</span>
                <span><sup>2</sup>National University of Singapore, Singapore</span>
                <span><sup>3</sup>Zhejiang University, Hangzhou, China</span>
                <span><sup>4</sup>Huazhong University of Science and Technology, Wuhan, China</span>                
            </div>

            <div style="font-size:15px">
              <span><sup>&ast;</sup>Corresponding author: wanghuan@westlake.edu.cn</span></br></br>
            </div>

            <div class="columns is-centered">
              <div class="column is-narrow">
                <figure class="image">
                  <img src="figure/wlu-logo.png" alt="WLU" style="height: 96px; object-fit: contain;">
                </figure>
              </div>
              <div class="column is-narrow">
                <figure class="image">
                  <img src="figure/nus-logo.jpg" alt="NUS" style="height: 96px; object-fit: contain;">
                </figure>
              </div>    
              <div class="column is-narrow">
                <figure class="image">
                  <img src="figure/zju-logo.jpg" alt="ZJU" style="height: 96px; object-fit: contain;">
                </figure>
              </div>
              <div class="column is-narrow">
                <figure class="image">
                  <img src="figure/hzu-logo.png" alt="HZU" style="height: 96px; object-fit: contain;">
                </figure>
              </div>          
            </div>
            

            <div class="columns is-centered">
              <div class="column is-narrow">
              <figure class="image is-256x128">
                <img src="figure/logo.jpg" alt="ENCODE Lab" style="width: 384px; height: 96px;">
              </figure>
              </div>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2505.18675"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>PDF</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2505.18675" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>ArXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/fscdc/ReasonMap"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- dataset Link. -->
                <span class="link-block">
                    <a href="https://huggingface.co/collections/FSCCS/reasonmap-688517b57d771707a5d64656"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face" style="width: 20px; height: 20px;">
                      </span>
                      <span>Dataset</span>
                    </a>
                  </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div align='center'>
          <a><img src="./figure/overview.png"  height="220" ></a>
        </div>
        <div class="content has-text-justified">
          Overview of ReasonMap. ReasonMap is a benchmark dataset designed to evaluate fine-grained visual reasoning abilities of MLLMs, encompassing 1,008 question–answer pairs constructed over high-resolution transit maps from 30 cities, spanning two question types and three templates.
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            Multimodal large language models (MLLMs) have recently achieved significant progress in visual tasks, including semantic scene understanding and text-image alignment, with reasoning variants enhancing performance on complex tasks involving mathematics and logic.
            However, their capacity for reasoning tasks involving fine-grained visual understanding remains insufficiently evaluated. To address this gap, we introduce ReasonMap, a benchmark designed to assess the fine-grained visual understanding and spatial reasoning abilities of MLLMs.
            ReasonMap encompasses high-resolution transit maps from 30 cities across 13 countries and includes 1,008 question-answer pairs spanning two question types and three templates. 
            Furthermore, we design a two-level evaluation pipeline that properly assesses answer correctness and quality.
            Comprehensive evaluations of 15 popular MLLMs, including both base and reasoning variants, reveal a counterintuitive pattern: among open-source models, base models outperform reasoning ones, while the opposite trend is observed in closed-source models. 
            Additionally, performance generally degrades when visual inputs are masked, indicating that while MLLMs can leverage prior knowledge to answer some questions, fine-grained visual reasoning tasks still require genuine visual perception for strong performance.
            Our benchmark study offers new insights into visual reasoning and contributes to investigating the gap between open-source and closed-source models.
          </div>
        </div>
      </div>
    </div>
  </section>



  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Experimental Results</h2>
          <div class="content has-text-justified">
            <p><strong>Table 1:</strong> Evaluations of various MLLMs on ReasonMap. <strong>S.</strong> represents short questions (max map score = 20), <strong>L.</strong> denotes long questions (max map score = 40). <strong>Bold</strong> is best per group; <u>Underline</u> is second best.</p>
  <div class="table-container">
  <table class="table is-bordered is-striped is-hoverable is-fullwidth is-size-7">
  <thead>
  <tr><th>Model</th><th>Type</th><th>Acc. (S.)</th><th>#Tokens (S.)</th><th>Acc. (L.)</th><th>#Tokens (L.)</th><th>Map Score (S. / L.)</th></tr>
  </thead>
  <tbody>
  <tr><td colspan="7" class="has-text-centered has-text-grey-light"><em>Open-source Models</em></td></tr>
  <tr><td>Qwen2.5-VL-3B-Instruct</td><td>Base</td><td>8.68%</td><td>42</td><td>7.99%</td><td>151</td><td>2.75 / 3.70</td></tr>
  <tr><td>Qwen2.5-VL-32B-Instruct</td><td>Base</td><td>16.49%</td><td>36</td><td>15.71%</td><td>112</td><td>3.88 / 6.84</td></tr>
  <tr><td>Qwen2.5-VL-72B-Instruct</td><td>Base</td><td><strong>26.65%<strong></td><td>33</td><td><strong>24.22%<strong></td><td>104</td><td><strong>5.09 / 8.80<strong></td></tr>
  <tr><td>InternVL3-38B</td><td>Base</td><td>14.84%</td><td>43</td><td>13.45%</td><td>68</td><td>3.48 / 6.31</td></tr>
  <tr><td>InternVL3-78B</td><td>Base</td><td><u>25.35%<u></td><td>33</td><td><u>19.62%<u></td><td>62</td><td><u>4.80 / 7.50<u></td></tr>
  <tr><td>Kimi-VL-A3B-Instruct</td><td>Base</td><td>12.76%</td><td>41</td><td>12.33%</td><td>41</td><td>3.30 / 5.37</td></tr>
  <tr><td>Kimi-VL-A3B-Thinking</td><td>Reasoning</td><td>5.47%</td><td>754</td><td>5.47%</td><td>1,287</td><td>2.44 / 3.17</td></tr>
  <tr><td>Skywork-R1V-38B</td><td>Reasoning</td><td>6.86%</td><td>645</td><td>3.21%</td><td>842</td><td>2.11 / 3.11</td></tr>
  <tr><td>QvQ-72B-Preview</td><td>Reasoning</td><td>9.03%</td><td>1,279</td><td>4.25%</td><td>1,619</td><td>1.59 / 1.55</td></tr>
  <tr><td colspan="7" class="has-text-centered has-text-grey-light"><em>Closed-source Models</em></td></tr>
  <tr><td>Doubao-115</td><td>Base</td><td>34.20%</td><td>32</td><td>38.02%</td><td>118</td><td>5.25 / 11.96</td></tr>
  <tr><td>OpenAI 4o</td><td>Base</td><td>41.15%</td><td>34</td><td>42.80%</td><td>58</td><td>6.84 / 13.57</td></tr>
  <tr><td>Doubao-415</td><td>Reasoning</td><td>43.14%</td><td>536</td><td><u>46.09%<u></td><td>1,796</td><td>7.33 / <u>14.67</u></td></tr>
  <tr><td>Doubao-428</td><td>Reasoning</td><td>37.15%</td><td>532</td><td>37.85%</td><td>2,167</td><td>5.52 / 11.73</td></tr>
  <tr><td>Gemini-2.5-Flash</td><td>Reasoning</td><td><u>46.09%<u></td><td>806</td><td>29.86%</td><td>1,419</td><td><u>7.64</u> / 9.98</td></tr>
  <tr><td>OpenAI o3</td><td>Reasoning</td><td><strong>63.02%<strong></td><td>1,236</td><td><strong>59.11%<strong></td><td>2,372</td><td><strong>9.53 / 17.96<strong></td></tr>
  </tbody>
  </table>
  </div>
          </div>
          <div class="content has-text-justified">
            <p><strong>Table 2:</strong> Evaluations of various MLLMs on ReasonMap <em>without visual inputs</em>. <strong>S.</strong> represents short questions (max map score = 20), <strong>L.</strong> denotes long questions (max map score = 40). <strong>Bold</strong> is best per group; <u>Underline</u> is second best. <span style="color:rgb(93,173,85);">Green</span> ↑ means improved, <span style="color:rgb(192,57,43);">Red</span> ↓ represents the value dropped from full input (Table 1).</p>
            <div class="table-container">
  <table class="table is-bordered is-striped is-hoverable is-fullwidth is-size-7">
  <thead>
  <tr><th>Model</th><th>Type</th><th>Acc. (S.)</th><th>#Tokens (S.)</th><th>Acc. (L.)</th><th>#Tokens (L.)</th><th>Map Score (S. / L.)</th></tr>
  </thead>
  <tbody>
    <tr><td colspan="7" class="has-text-centered has-text-grey-light"><em>Open-source Models</em></td></tr>
    <tr><td>Qwen2.5-VL-3B-Instruct</td><td>Base</td><td>9.38% <span style="color:rgb(93,173,85); font-size:0.75em;">↑ <b>0.7%</b></span></td><td>47</td><td>9.72% <span style="color:rgb(93,173,85); font-size:0.75em;">↑ <b>1.73%</b></span></td><td>147</td><td>2.93 <span style="color:rgb(93,173,85); font-size:0.75em;">↑ <b>0.18</b></span> / 4.51 <span style="color:rgb(93,173,85); font-size:0.75em;">↑ <b>0.81</b></span></td></tr>
    <tr><td>Qwen2.5-VL-72B-Instruct</td><td>Base</td><td><strong>16.41%</strong> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>10.24%</b></span></td><td>28</td><td><strong>15.71%</strong> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>8.51%</b></span></td><td>108</td><td><strong>4.03</strong> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>1.06</b></span> / <strong>6.49</strong> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>2.31</b></span></td></tr>
    <tr><td>Kimi-VL-A3B-Instruct</td><td>Base</td><td><u>11.81%</u> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>0.95%</b></span></td><td>41</td><td><u>9.81%</u> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>2.52%</b></span></td><td>49</td><td><u>3.37</u> <span style="color:rgb(93,173,85); font-size:0.75em;">↑ <b>0.07</b></span> / <u>5.32</u> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>0.05</b></span></td></tr>
    <tr><td>Kimi-VL-A3B-Thinking</td><td>Reasoning</td><td>4.17% <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>1.30%</b></span></td><td>1,039</td><td>2.08% <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>3.39%</b></span></td><td>1,755</td><td>2.06 <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>0.38</b></span> / 1.64 <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>1.53</b></span></td></tr>
    <tr><td colspan="7" class="has-text-centered has-text-grey-light"><em>Closed-source Models</em></td></tr>
    <tr><td>Doubao-115</td><td>Base</td><td><u>13.72%</u> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>20.48%</b></span></td><td>34</td><td><u>13.98%</u> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>24.04%</b></span></td><td>99</td><td><u>3.50</u> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>1.75</b></span> / <u>6.48</u> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>5.48</b></span></td></tr>
    <tr><td>Doubao-415</td><td>Reasoning</td><td><strong>21.53%</strong> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>21.61%</b></span></td><td>352</td><td><strong>17.19%</strong> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>28.90%</b></span></td><td>1,047</td><td><strong>4.85</strong> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>2.48</b></span> / <strong>7.68</strong> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>6.99</b></span></td></tr>
  </tbody>  
  </table>
  </div>
          </div>
          <div class="content has-text-justified">
        
            <p align="center">
              <a>
                <svg width="300" height="300" viewBox="270 160 350 250">
                  <image href="figure/short_radar.svg"></image>
                </svg>
              </a>
              <a>
                <svg width="300" height="300" viewBox="270 160 350 250">
                  <image href="figure/long_radar.svg"></image>
                </svg>
              </a>
            </p>


            

            <p><strong>Figure 1:</strong> Accuracy across different cities for four representative MLLMs 
              (<span style="color:rgb(174,199,232);">Qwen2.5-VL-72B-I</span>, 
              <span style="color:rgb(255,187,120);">InternVL3-78B</span>, 
              <span style="color:rgb(152,223,138);">OpenAI o3</span>, and 
              <span style="color:rgb(255,152,150);">Doubao-415</span>, <i>left</i> for short questions, <i>right</i> for long questions). 
              Each city is marked with the corresponding map difficulty and the country flag. 
              Each city in the test set provides a specific number of samples per model: 
              32 samples for Auckland, 34 for Los Angeles, 7 for Miami, 35 for Lisboa, 
              18 for Geneva, 40 for Beijing, 39 for Hangzhou, 17 for Budapest, 
              39 for Singapore, 40 for Rome, and 11 for Toronto.
            </p>    

          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- <section class="section"> -->
    <!-- <div class="container is-max-desktop"> -->
      <!-- <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-justified">
            <p><strong>Table 2:</strong> Evaluations of various MLLMs on ReasonMap <em>without visual inputs</em>. <strong>S.</strong> represents short questions (max map score = 20), <strong>L.</strong> denotes long questions (max map score = 40). <strong>Bold</strong> is best per group; <u>Underline</u> is second best. <span style="color:rgb(93,173,85);">Green</span> ↑ means improved, <span style="color:rgb(192,57,43);">Red</span> ↓ represents the value dropped from full input (Table 1).</p>
            <div class="table-container">
  <table class="table is-bordered is-striped is-hoverable is-fullwidth is-size-7">
  <thead>
  <tr><th>Model</th><th>Type</th><th>Acc. (S.)</th><th>#Tokens (S.)</th><th>Acc. (L.)</th><th>#Tokens (L.)</th><th>Map Score (S. / L.)</th></tr>
  </thead>
  <tbody>
    <tr><td colspan="7" class="has-text-centered has-text-grey-light"><em>Open-source Models</em></td></tr>
    <tr><td>Qwen2.5-VL-3B-Instruct</td><td>Base</td><td>9.38% <span style="color:rgb(93,173,85); font-size:0.75em;">↑ <b>0.7%</b></span></td><td>47</td><td>9.72% <span style="color:rgb(93,173,85); font-size:0.75em;">↑ <b>1.73%</b></span></td><td>147</td><td>2.93 <span style="color:rgb(93,173,85); font-size:0.75em;">↑ <b>0.18</b></span></td></tr>
    <tr><td>Qwen2.5-VL-72B-Instruct</td><td>Base</td><td><strong>16.41%</strong> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>10.24%</b></span></td><td>28</td><td><strong>15.71%</strong> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>8.51%</b></span></td><td>108</td><td><strong>4.03</strong> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>1.06</b></span></td></tr>
    <tr><td>Kimi-VL-A3B-Instruct</td><td>Base</td><td><u>11.81%</u> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>0.95%</b></span></td><td>41</td><td><u>9.81%</u> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>2.52%</b></span></td><td>49</td><td><u>3.37</u> <span style="color:rgb(93,173,85); font-size:0.75em;">↑ <b>0.07</b></span></td></tr>
    <tr><td>Kimi-VL-A3B-Thinking</td><td>Reasoning</td><td>4.17% <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>1.30%</b></span></td><td>1,039</td><td>2.08% <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>3.39%</b></span></td><td>1,755</td><td>2.06 <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>0.38</b></span></td></tr>
    <tr><td colspan="7" class="has-text-centered has-text-grey-light"><em>Closed-source Models</em></td></tr>
    <tr><td>Doubao-115</td><td>Base</td><td><u>13.72%</u> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>20.48%</b></span></td><td>34</td><td><u>13.98%</u> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>24.04%</b></span></td><td>99</td><td><u>3.50</u> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>1.75</b></span></td></tr>
    <tr><td>Doubao-415</td><td>Reasoning</td><td><strong>21.53%</strong> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>21.61%</b></span></td><td>352</td><td><strong>17.19%</strong> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>28.90%</b></span></td><td>1,047</td><td><strong>4.85</strong> <span style="color:rgb(192,57,43); font-size:0.75em;">↓ <b>2.48</b></span></td></tr>
  </tbody>  
  </table>
  </div>
          </div>
        </div>
      </div> -->
    <!-- </div> -->
  <!-- </section> -->
  

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">How to use ReasonMap for evaluating your model?</h2>
          <div class="content has-text-justified">
            <p>ReasonMap is designed to evaluate the fine-grained visual reasoning abilities of MLLMs. To use ReasonMap for evaluation, follow these steps:</p>
            <ol>
              <li>Download the ReasonMap dataset from the Hugging Face repository: <a href="https://huggingface.co/datasets/FSCCS/ReasonMap">ReasonMap</a>.
                  <div style="position: relative; border: 1px solid #ddd; border-radius: 5px; padding: 10px; background-color: #f9f9f9;">
                    <button id="copyButton" style="position: absolute; top: 5px; right: 10px; background-color: #3273dc; color: white; border: none; padding: 5px 10px; border-radius: 3px; cursor: pointer;" onclick="copyToClipboard()">Copy</button>
                    <pre style="margin: 0; overflow-x: auto;"><code>from datasets import load_dataset

ds = load_dataset("FSCCS/ReasonMap")</code></pre>
                  </div>

                  <script>
                    function copyToClipboard() {
                      const code = `from datasets import load_dataset

                  ds = load_dataset("FSCCS/ReasonMap")`;
                      navigator.clipboard.writeText(code).then(() => {
                        const copyButton = document.getElementById("copyButton");
                        copyButton.textContent = "Copied";
                        copyButton.style.backgroundColor = "#28a745"; // Optional: Change button color to green
                        setTimeout(() => {
                          copyButton.textContent = "Copy";
                          copyButton.style.backgroundColor = "#3273dc"; // Reset button color
                        }, 2000); // Reset after 2 seconds
                      }).catch(err => {
                        console.error("Failed to copy: ", err);
                      });
                    }
                  </script>
              </li>
              <li>Download our evaluation code from the GitHub repository: <a href="https://github.com/fscdc/ReasonMap">Evaluation Code</a>.
                <div style="position: relative; border: 1px solid #ddd; border-radius: 5px; padding: 10px; background-color: #f9f9f9;">
                  <button id="copyButton1" style="position: absolute; top: 5px; right: 10px; background-color: #3273dc; color: white; border: none; padding: 5px 10px; border-radius: 3px; cursor: pointer;" onclick="copyToClipboard1()">Copy</button>
                  <pre style="margin: 0; overflow-x: auto;"><code>git clone https://github.com/fscdc/ReasonMap.git</code></pre>
                </div>

                <script>
                  function copyToClipboard1() {
                    const code = `git clone https://github.com/fscdc/ReasonMap.git`;
                    navigator.clipboard.writeText(code).then(() => {
                      const copyButton = document.getElementById("copyButton1");
                      copyButton.textContent = "Copied";
                      copyButton.style.backgroundColor = "#28a745"; // Optional: Change button color to green
                      setTimeout(() => {
                        copyButton.textContent = "Copy";
                        copyButton.style.backgroundColor = "#3273dc"; // Reset button color
                      }, 2000); // Reset after 2 seconds
                    }).catch(err => {
                      console.error("Failed to copy: ", err);
                    });
                  }
                </script>
              </li>
              <li>Setup conda env.
                <div style="position: relative; border: 1px solid #ddd; border-radius: 5px; padding: 10px; background-color: #f9f9f9;">
                  <button id="copyButton2" style="position: absolute; top: 5px; right: 10px; background-color: #3273dc; color: white; border: none; padding: 5px 10px; border-radius: 3px; cursor: pointer;" onclick="copyToClipboard2()">Copy</button>
                  <pre style="margin: 0; overflow-x: auto;"><code>conda create -n reasonmap python=3.10
conda activate reasonmap
pip install torchvision==0.17.2
pip install torch==2.2.2
pip install numpy==1.24.3
pip install transformers, datasets
pip install flash-attn # if not work, please install flash-attn from source (<a href="https://github.com/Dao-AILab/flash-attention/releases/tag/v2.7.4.post1" target="_blank">LINK</a>)</code></pre>
                </div>

                <script>
                  function copyToClipboard2() {
                    const code = `conda create -n reasonmap python=3.10
conda activate reasonmap
pip install torchvision==0.17.2
pip install torch==2.2.2
pip install numpy==1.24.3
pip install transformers, datasets
pip install flash-attn # if not work, please install flash-attn from source (<a href="https://github.com/Dao-AILab/flash-attention/releases/tag/v2.7.4.post1" target="_blank">LINK</a>)`;
                    navigator.clipboard.writeText(code).then(() => {
                      const copyButton = document.getElementById("copyButton2");
                      copyButton.textContent = "Copied";
                      copyButton.style.backgroundColor = "#28a745"; // Optional: Change button color to green
                      setTimeout(() => {
                        copyButton.textContent = "Copy";
                        copyButton.style.backgroundColor = "#3273dc"; // Reset button color
                      }, 2000); // Reset after 2 seconds
                    }).catch(err => {
                      console.error("Failed to copy: ", err);
                    });
                  }
                </script>
              </li>
              <li>Then you can do your work (for closed-source models, please fill 'to-add-your-api-key' with your api keys)</li>
              <li><p>If you encounter any issues, please open an issue at <a href="https://github.com/fscdc/ReasonMap/issues" target="_blank">ReasonMap Issues</a>, and we will assist you as soon as possible.</p></li>
            </ol>
          </div>
        </div>
      </div>
    </div>
  </section>




  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{feng2025can,
  title={Can MLLMs Guide Me Home? A Benchmark Study on Fine-Grained Visual Reasoning from Transit Maps},
  author={Feng, Sicheng and Wang, Song and Ouyang, Shuyi and Kong, Lingdong and Song, Zikai and Zhu, Jianke and Wang, Huan and Wang, Xinchao},
  journal={arXiv preprint arXiv:2505.18675},
  year={2025},
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div align="center" class="container">
      <div class="columns is-centered">
        <div class="content">
          This website is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
